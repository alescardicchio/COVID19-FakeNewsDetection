{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librerie\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import textstat\n",
    "from lexicalrichness import LexicalRichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "dataset = pd.read_csv(\"./dataset/corona_fake.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formattazione\n",
    "dataset['label'] = dataset['label'].str.upper()  #trasforma tutta la colonna label in maiuscolo\n",
    "dataset['source'] = dataset['source'].str.lower()  # trasorma tutta la colonna source in minuscolo\n",
    "dataset.loc[dataset['source'] == 'facebook', ['source']] = 'https://facebook.com/'\n",
    "dataset.loc[dataset['source'] == 'twitter', ['source']] = 'https://twitter.com/'\n",
    "dataset.loc[dataset['source'] == 'youtube', ['source']] = 'https://youtube.com/'\n",
    "\n",
    "# assegnazione esplicita delle label in seguito ad accertamenti\n",
    "dataset.loc[5]['label'] = 'FAKE'\n",
    "dataset.loc[15]['label'] = 'TRUE'\n",
    "dataset.loc[43]['label'] = 'FAKE'\n",
    "dataset.loc[131]['label'] = 'TRUE'\n",
    "dataset.loc[242]['label'] = 'FAKE'\n",
    "\n",
    "dataset.text.fillna(dataset.title, inplace=True)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# replace dei NaN\n",
    "dataset.title.fillna('missing', inplace=True)\n",
    "dataset.source.fillna('missing', inplace=True)\n",
    "\n",
    "#dataset.label.value_counts()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install plotly.express\n",
    "#%pip install plotly.figure_factory\n",
    "#%pip install plotly.graph_objects\n",
    "#%pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lettere maiuscole nel titolo\n",
    "### • Contiamo il numero di lettere maiuscole in ogni titolo.\n",
    "### • Calcoliamo la percentuale di lettere maiuscole nel corpo di ogni articolo anzichè contarne il numero , a causa della diversa lunghezza degli articoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['title_num_uppercase'] = dataset['title'].str.count(r'[A-Z]')\n",
    "dataset['text_num_uppercase'] = dataset['text'].str.count(r'[A-Z]')\n",
    "dataset['text_len'] = dataset['text'].str.len()\n",
    "dataset['text_pct_uppercase'] = dataset.text_num_uppercase.div(dataset.text_len)\n",
    "\n",
    "x1 = dataset.loc[dataset['label']=='TRUE']['title_num_uppercase']\n",
    "x2 = dataset.loc[dataset['label'] == 'FAKE']['title_num_uppercase']\n",
    "group_labels = ['TRUE', 'FAKE']\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig = ff.create_distplot([x1, x2], group_labels,colors=colors)\n",
    "\n",
    "fig.update_layout(title_text='Distribuzione delle lettere maiuscole nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=x1, name='TRUE',\n",
    "                marker_color = 'rgb(0, 0, 100)'))\n",
    "fig.add_trace(go.Box(y=x2, name = 'FAKE',\n",
    "                marker_color = 'rgb(0, 200, 200)'))\n",
    "fig.update_layout(title_text='Box plot delle lettere maiuscole nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In media, le fake news presentano un maggior numero di lettere maiuscole nel titolo.\n",
    "Questo fa pensare che le fake news si rivolgono a un pubblico che potrebbe essere influenzato dai titoli.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words nel titolo\n",
    "### • Contiamo il numero di stop words in ogni titolo.\n",
    "### • Calcoliamo la percentuale di stop words nel corpo di ogni articolo anzichè contarne il numero , a causa della diversa lunghezza degli articoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords    \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['title_num_stop_words'] = dataset['title'].str.split().apply(lambda x: len(set(x) & stop_words))\n",
    "dataset['text_num_stop_words'] = dataset['text'].str.split().apply(lambda x: len(set(x) & stop_words))\n",
    "dataset['text_word_count'] = dataset['text'].apply(lambda x: len(str(x).split()))\n",
    "dataset['text_pct_stop_words'] = dataset['text_num_stop_words'] / dataset['text_word_count']\n",
    "\n",
    "x1 = dataset.loc[dataset['label']=='TRUE']['title_num_stop_words']\n",
    "x2 = dataset.loc[dataset['label'] == 'FAKE']['title_num_stop_words']\n",
    "group_labels = ['TRUE', 'FAKE']\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    [x1, x2], group_labels,colors=colors)\n",
    "\n",
    "fig.update_layout(title_text='Distribuzione delle Stop Words nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=x1, name='TRUE', marker_color = 'rgb(0, 0, 100)'))\n",
    "fig.add_trace(go.Box(y=x2, name = 'FAKE', marker_color = 'rgb(0, 200, 200)'))\n",
    "fig.update_layout(title_text='Box plot delle Stop Words nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I titoli delle fake news hanno meno stop-words rispetto alle real-news.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nomi propri nel titolo\n",
    "### • Contiamo il numero di nomi prorpri (NNP) in ogni titolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['text_num_uppercase', 'text_len', 'text_num_stop_words', 'text_word_count'], axis=1, inplace=True)\n",
    "\n",
    "dataset['token'] = dataset.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)\n",
    "dataset['pos_tags'] = dataset.apply(lambda row: nltk.pos_tag(row['token']), axis=1)\n",
    "\n",
    "tag_count_dataset = pd.DataFrame(dataset['pos_tags'].map(lambda x: Counter(tag[1] for tag in x)).to_list())\n",
    "dataset = pd.concat([dataset, tag_count_dataset], axis=1).fillna(0).drop(['pos_tags', 'token'], axis=1)\n",
    "\n",
    "dataset = dataset[['title', 'text', 'source', 'label', 'title_num_uppercase', 'text_pct_uppercase', 'title_num_stop_words', 'text_pct_stop_words', 'NNP']].rename(columns={'NNP': 'NNP_title'})\n",
    "\n",
    "x1 = dataset.loc[dataset['label']=='TRUE']['NNP_title']\n",
    "x2 = dataset.loc[dataset['label'] == 'FAKE']['NNP_title']\n",
    "\n",
    "group_labels = ['TRUE', 'FAKE']\n",
    "\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    [x1, x2], group_labels,colors=colors)\n",
    "\n",
    "fig.update_layout(title_text='Numero di nomi propri nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Box(y=x1, name='TRUE',\n",
    "                marker_color = 'rgb(0, 0, 100)'))\n",
    "fig.add_trace(go.Box(y=x2, name = 'FAKE',\n",
    "                marker_color = 'rgb(0, 200, 200)'))\n",
    "fig.update_layout(title_text='Box plot dei nomi propri nel titolo', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I titoli delle fake-news presentano più nomi propri. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final word cloud after all the cleaning and pre-processing\n",
    "# import matplotlib.pyplot as plt\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "# comment_words = ' '\n",
    "# stopwords = set(STOPWORDS) \n",
    "\n",
    "# iterate through the csv file \n",
    "# for val in df.comment: \n",
    "\n",
    "   # typecaste each val to string \n",
    "   # val = str(val) \n",
    "\n",
    "   # split the value \n",
    "   # tokens = val.split() \n",
    "\n",
    "# Converts each token into lowercase \n",
    "# for i in range(len(tokens)): \n",
    "#    tokens[i] = tokens[i].lower() \n",
    "\n",
    "# for words in tokens: \n",
    "#    comment_words = comment_words + words + ' '\n",
    "\n",
    "\n",
    "# wordcloud = WordCloud(width = 800, height = 800, \n",
    "#            background_color ='white', \n",
    "#            stopwords = stopwords, \n",
    "#            min_font_size = 10).generate(comment_words) \n",
    "\n",
    "# plot the WordCloud image                        \n",
    "# plt.figure(figsize = (8, 8), facecolor = None) \n",
    "# plt.imshow(wordcloud) \n",
    "# plt.axis(\"off\") \n",
    "# plt.tight_layout(pad = 0) \n",
    "\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nel complesso, questi risultati suggeriscono che gli autori di fake-news cercano di attirare l'attenzione utilizzando le parole in maiuscolo nei titoli e concentrando quante più key-words possibili nei titoli saltando le stop-word e aumentando i nomi propri. Analizziamo se lo stesso avviene anche nei corpi degli articoli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lettere maiuscole nel corpo degli articoli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dataset.loc[dataset['label']=='TRUE']['text_pct_uppercase']\n",
    "x2 = dataset.loc[dataset['label'] == 'FAKE']['text_pct_uppercase']\n",
    "\n",
    "group_labels = ['TRUE', 'FAKE']\n",
    "\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    [x1, x2], group_labels,colors=colors)\n",
    "\n",
    "fig.update_layout(title_text='Percentuale di lettere maiuscole nel corpo degli articoli', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In media, le fake news presentano un maggior numero di lettere maiuscole nel corpo degli articoli.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words nel corpo degli articoli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dataset.loc[dataset['label']=='TRUE']['text_pct_stop_words']\n",
    "x2 = dataset.loc[dataset['label'] == 'FAKE']['text_pct_stop_words']\n",
    "\n",
    "group_labels = ['TRUE', 'FAKE']\n",
    "\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig = ff.create_distplot(\n",
    "    [x1, x2], group_labels,colors=colors)\n",
    "\n",
    "fig.update_layout(title_text='Percentuale di Stop Words nel corpo degli articoli', template=\"plotly_white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non ci sono differenze significative tra le percentuali di stop word nelle fake e nelle real news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harvard Health Publishing vs. Natural News\n",
    "#### Natural News è un sito di notizie false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = dataset.loc[dataset['source']=='https://www.health.harvard.edu/']['text_pct_stop_words']\n",
    "x2 = dataset.loc[dataset['source']=='https://www.naturalnews.com/']['text_pct_stop_words']\n",
    "\n",
    "x3 = dataset.loc[dataset['source']=='https://www.health.harvard.edu/']['text_pct_uppercase']\n",
    "x4 = dataset.loc[dataset['source']=='https://www.naturalnews.com/']['text_pct_uppercase']\n",
    "\n",
    "x5 = dataset.loc[dataset['source']=='https://www.health.harvard.edu/']['NNP_title']\n",
    "x6 = dataset.loc[dataset['source']=='https://www.naturalnews.com/']['NNP_title']\n",
    "\n",
    "\n",
    "\n",
    "group_labels = ['Health Harvard', 'Natural News']\n",
    "\n",
    "colors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n",
    "\n",
    "fig1 = ff.create_distplot([x1, x2], group_labels,colors=colors)\n",
    "fig1.update_layout(title_text='Percentuale di Stop Words nel corpo degli articoli', template=\"plotly_white\")\n",
    "fig1.show()\n",
    "\n",
    "fig2 = ff.create_distplot([x3, x4], group_labels,colors=colors)\n",
    "fig2.update_layout(title_text='Percentuale di lettere maiuscole nel corpo degli articoli', template=\"plotly_white\")\n",
    "fig2.show()\n",
    "\n",
    "fig3 = ff.create_distplot([x5, x6], group_labels,colors=colors)\n",
    "fig3.update_layout(title_text='Numero di nomi propri nel titolo degli articoli', template=\"plotly_white\")\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come volevasi dimostrare, gli articoli di Natural News usano molte meno stop words rispetto a Healt Publishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "### Per analizzare in modo approfondito gli articoli fake e real, calcoliamo alcune features basate sui corpi degli articoli:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Usiamo un part-of-speech tagger e contiamo il numero di volte in cui ogni tag compare nell'articolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['token'] = dataset.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "dataset['pos_tags'] = dataset.apply(lambda row: nltk.pos_tag(row['token']), axis=1)\n",
    "\n",
    "tag_count_dataset = pd.DataFrame(dataset['pos_tags'].map(lambda x: Counter(tag[1] for tag in x)).to_list())\n",
    "\n",
    "dataset = pd.concat([dataset, tag_count_dataset], axis=1).fillna(0).drop(['pos_tags', 'token'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Numero di forme negative e interrogative nel corpo degli articoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['num_negation'] = dataset['text'].str.lower().str.count(\"no|not|never|none|nothing|nobody|neither|nowhere|hardly|scarcely|barely|doesn’t|isn’t|wasn’t|shouldn’t|wouldn’t|couldn’t|won’t|can't|don't\")\n",
    "\n",
    "dataset['num_interrogatives_title'] = dataset['title'].str.lower().str.count(\"what|who|when|where|which|why|how\")\n",
    "dataset['num_interrogatives_text'] = dataset['text'].str.lower().str.count(\"what|who|when|where|which|why|how\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_ease = []\n",
    "for doc in dataset['text']:\n",
    "    reading_ease.append(textstat.flesch_reading_ease(doc))\n",
    "    \n",
    "smog = []\n",
    "for doc in dataset['text']:\n",
    "    smog.append(textstat.smog_index(doc))\n",
    "    \n",
    "kincaid_grade = []\n",
    "for doc in dataset['text']:\n",
    "    kincaid_grade.append(textstat.flesch_kincaid_grade(doc))\n",
    "    \n",
    "liau_index = []\n",
    "for doc in dataset['text']:\n",
    "    liau_index.append(textstat.coleman_liau_index(doc))\n",
    "    \n",
    "readability_index = []\n",
    "for doc in dataset['text']:\n",
    "    readability_index.append(textstat.automated_readability_index(doc))\n",
    "\n",
    "readability_score = []\n",
    "for doc in dataset['text']:\n",
    "    readability_score.append(textstat.dale_chall_readability_score(doc))\n",
    "    \n",
    "difficult_words = []\n",
    "for doc in dataset['text']:\n",
    "    difficult_words.append(textstat.difficult_words(doc))\n",
    "\n",
    "write_formula = []\n",
    "for doc in dataset['text']:\n",
    "    write_formula.append(textstat.linsear_write_formula(doc))\n",
    "\n",
    "gunning_fog = []\n",
    "for doc in dataset['text']:\n",
    "    gunning_fog.append(textstat.gunning_fog(doc))\n",
    "\n",
    "text_standard = []\n",
    "for doc in dataset['text']:\n",
    "    text_standard.append(textstat.text_standard(doc))\n",
    "    \n",
    "dataset['flesch_reading_ease'] = reading_ease\n",
    "dataset['smog_index'] = smog\n",
    "dataset['flesch_kincaid_grade'] = kincaid_grade\n",
    "dataset['automated_readability_index'] = readability_index\n",
    "dataset['dale_chall_readability_score'] = readability_score\n",
    "dataset['difficult_words'] = difficult_words\n",
    "dataset['linsear_write_formula'] = write_formula\n",
    "dataset['gunning_fog'] = gunning_fog\n",
    "dataset['text_standard'] = text_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttr = []\n",
    "for doc in dataset['text']:\n",
    "    lex = LexicalRichness(doc)\n",
    "    ttr.append(lex.ttr)\n",
    "\n",
    "dataset['ttr'] = ttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['num_powerWords_text'] = dataset['text'].str.lower().str.count('improve|trust|immediately|discover|profit|learn|know|understand|powerful|best|win|more|bonus|exclusive|extra|you|free|health|guarantee|new|proven|safety|money|now|today|results|protect|help|easy|amazing|latest|extraordinary|how to|worst|ultimate|hot|first|big|anniversary|premiere|basic|complete|save|plus|create')\n",
    "dataset['num_casualWords_text'] = dataset['text'].str.lower().str.count('make|because|how|why|change|use|since|reason|therefore|result')\n",
    "dataset['num_tentativeWords_text'] = dataset['text'].str.lower().str.count('may|might|can|could|possibly|probably|it is likely|it is unlikely|it is possible|it is probable|tends to|appears to|suggests that|seems to')\n",
    "dataset['num_emotionWords_text'] = dataset['text'].str.lower().str.count('ordeal|outrageous|provoke|repulsive|scandal|severe|shameful|shocking|terrible|tragic|unreliable|unstable|wicked|aggravate|agony|appalled|atrocious|corruption|damage|disastrous|disgusted|dreadatasetul|eliminate|harmful|harsh|inconsiderate|enraged|offensive|aggressive|frustrated|controlling|resentful|anger|sad|fear|malicious|infuriated|critical|violent|vindictive|furious|contrary|condemning|sarcastic|poisonous|jealous|retaliating|desperate|alienated|unjustified|violated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext(string):\n",
    "    text = string.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"http(\\S)+\",' ',text)    \n",
    "    text = re.sub(r\"www(\\S)+\",' ',text)\n",
    "    text = re.sub(r\"&\",' and ',text)  \n",
    "    text = text.replace('&amp',' ')\n",
    "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text)\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].map(lambda x: cleantext(x))\n",
    "dataset['title'] = dataset['title'].map(lambda x: cleantext(x))\n",
    "dataset['source'] = dataset['source'].map(lambda x: cleantext(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\"TRUE\":1,\"FAKE\":0}\n",
    "dataset[\"label\"].replace(classes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i,j] >= threshold and (corr_matrix.columns[j] not in col_corr)):\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "                if colname in dataset.columns:\n",
    "                    del dataset[colname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(dataset, test_size = 0.2, random_state = 0)\n",
    "X_train, y_train = train.drop(['title', 'text', 'source', 'label', 'text_standard'], axis = 1), train['label']\n",
    "X_test, y_test = test.drop(['title', 'text', 'source', 'label', 'text_standard'], axis = 1), test['label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(pred, true):\n",
    "    print(\"Accuracy : \", accuracy_score(pred, true))\n",
    "    print(\"Precison : \", precision_score(pred, true, pos_label=1))\n",
    "    print(\"Recall : \", recall_score(pred, true))\n",
    "    print(\"F1 : \", f1_score(pred, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier(criterion = 'entropy')\n",
    "model = model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model = model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model = model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model = model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model = model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(dual=False)\n",
    "model = svc.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear', C = 1.0)\n",
    "model = clf.fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=50, learning_rate=1)\n",
    "model = abc.fit(X_train, y_train)  \n",
    "pred = model.predict(X_test)\n",
    "print_metrices(pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "229ec3f2be34d1c2a4a92117be2cab0262b83750a13adfba0c371deb50626d86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('DeepLeaning_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
